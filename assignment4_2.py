# -*- coding: utf-8 -*-
"""Assignment4.2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11wPaSAdaHPz2xmwJ1g2EAlrp1ELbPI-T
"""

import numpy as np 
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import cifar10,mnist

(x_train,y_train),(x_test,y_test) = cifar10.load_data()

Ntr = x_train.shape[0]
Nte = x_test.shape[0]
Din = 3072

x_train = x_train[range(Ntr),:]
x_test = x_test[range(Nte),:]
y_train = y_train[range(Ntr)]
y_test=y_test[range(Nte)]
k=len(np.unique(y_train))

y_train = tf.keras.utils.to_categorical(y_train,num_classes=k)
y_test = tf.keras.utils.to_categorical(y_test,num_classes=k)
print("x_train - > ",x_train.shape) #training images
print("y_train - > ",y_train.shape) #labels
print("x_test - > ",x_test.shape) #training images
print("y_test - > ",y_test.shape)

x_train = np.reshape(x_train,(Ntr,Din))
x_test = np.reshape(x_test,(Nte,Din))
x_train = x_train.astype('float32')
x_test = x_test.astype("float32")

mean_image = np.mean(x_train,axis = 0)
x_train = x_train - mean_image
x_test = x_test - mean_image

H=200
std =1e-6
w1 = std*np.random.randn(Din,H)
w2 = std*np.random.randn(H,k)
b1 =np.zeros(H)
b2 = np.zeros(k)
batch_size = Ntr

iterations = round(Ntr/batch_size)*300
lr = 1.4e-2
lr_decay = 0.999
reg = 5e-6
loss_history =[]
train_acc_history = []
val_acc_history = []

for t in range(iterations):
  batch_indices = np.random.choice(Ntr,batch_size)
  x=x_train[batch_indices]
  y=y_train[batch_indices]
  h=1.0/(1.0+np.exp(-(x.dot(w1)+b1)))
  y_pred =h.dot(w2)+b2
  loss= 1./batch_size*np.square(y_pred-y).sum()+reg*(np.sum(w2*w2)+np.sum(w1*w1))
  loss_history.append(loss)
  if t%10 == 0:
    print('iterations %d / %d:loss %f'%(t,iterations,loss))
  
  dy_pred = 1./batch_size*2.0*(y_pred-y)
  dw2 = h.T.dot(dy_pred) + reg*w2
  db2 = dy_pred.sum(axis=0)
  dh = dy_pred.dot(w2.T)
  dw1 = x.T.dot(dh*h*(1-h))+reg*w1
  db1 =(dh*h*(1-h)).sum(axis =0)
  w1 -= lr*dw1
  w2 -= lr*dw2
  b1 -= lr*db1
  b2 -= lr*db2
  lr *= lr_decay

fig,ax =plt.subplots(1,10)
fig.set_size_inches(32,10)
print(np.min(w1))
print(np.max(w1))

for i in range(10):
  img = w1[:,i].reshape(32,32,3)
  nor_img =255*(img-np.min(w1))/(np.max(w1)-np.min(w1))
  ax[i].imshow(nor_img.astype('uint8'))
plt.show()

plt.plot(loss_history)
plt.xlabel("iterations")
plt.ylabel("Loss")
plt.title("Loss history")
plt.show()

x_t = x_train
print("x_train->",x_t.shape)
h=1.0/(1.0+np.exp(-(x_t.dot(w1)+b1)))
y_pred = h.dot(w2)+b2

train_acc = 1.0 - 1/(Ntr*9)*(np.abs(np.argmax(y_train,axis=1)-np.argmax(y_pred,axis=1))).sum()
print("train_acc =",train_acc)

x_t=x_test
print("x_test->",x_t.shape)
h=1.0/(1.0+np.exp(-(x_t.dot(w1)+b1)))
y_pred = h.dot(w2)+b2

test_acc = 1.0-1/(Nte*9)*(np.abs(np.argmax(y_test,axis=1)-np.argmax(y_pred,axis=1))).sum()
print("test_acc = ",test_acc)